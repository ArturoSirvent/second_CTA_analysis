{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Vamos a hacer unos modelos para la predicción de energía.\n",
    " Esto es casi igual que lo de la clasificación pero tenemos que hacerlo con las labels de energia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#importamos librerias\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/asirvent/second_CTA_analysis/src/CTA-data-analisis-library/')\n",
    "\n",
    "import os \n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import numpy as np \n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "import psutil\n",
    "import re\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "from numba import cuda\n",
    "import gc\n",
    "\n",
    "#propias\n",
    "import unzipdata_and_first_treatments as manipulate\n",
    "import loaddata4use\n",
    "import model_creation_functions as models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#enviroment variables\n",
    "base_dir=\"/home/asirvent/second_CTA_analysis\"\n",
    "npy_final_dir=f\"{base_dir}/datos/elementos_npy\"\n",
    "base_dir_elementos=f\"{base_dir}/datos/elementos\"\n",
    "elements=['gamma', 'electron']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runs_disponibles(npy_dir,elements):\n",
    "    lista=[]\n",
    "    for i in elements:\n",
    "        npy_element_dir=os.path.join(npy_dir,\"npy_\"+i)\n",
    "        runs=[int(re.search(\"run_([0-9]{3})_0\\.npy\",i).group(1)) for i in os.listdir(npy_element_dir) if re.search(\"run_([0-9]{3})_0\\.npy\",i)]\n",
    "        lista.append(runs)\n",
    "    return lista\n",
    "\n",
    "\n",
    "def new_create_main_list_runs(number_runs_per_element,posibles_runs):\n",
    "    #esto es aleatorio por defecto, porque es lo unico que necesito por ahora    \n",
    "    final=[]\n",
    "    for ind,lista_runs_element in enumerate(posibles_runs):\n",
    "        final.append(random.sample(lista_runs_element,number_runs_per_element[ind]))\n",
    "    return final\n",
    "\n",
    "#tenemos que hacer un ligero cambio porque se estan cargando con los ejes cambiados\n",
    "def cambiar_ejes_lista(lista):\n",
    "    for i,j in enumerate(lista):\n",
    "        lista[i]=np.swapaxes(j,1,2)\n",
    "    return lista\n",
    "\n",
    "def get_all_size(local_vars):\n",
    "    #local_vars = list(locals().items())\n",
    "    total=0\n",
    "    for var, obj in local_vars:\n",
    "        total+=sys.getsizeof(obj)\n",
    "    total= total >> 20\n",
    "    return total # its in Mb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chose_runs=runs_disponibles(npy_final_dir,elements)\n",
    "chose_runs[0].remove(2)\n",
    "chose_runs[0].remove(2)\n",
    "chose_runs[0].remove(3)\n",
    "chose_runs[0].remove(3)\n",
    "chose_runs[0].remove(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opciones_filtros=[\n",
    "    [[16, 32], [64, 128], [128, 64], [64, 32]],\n",
    "    [[32,64],[64,128],[128,64,32]],\n",
    "    [[16,32],[32,64],[64,32,16]]]\n",
    "\n",
    "opciones_filtros_last=[\n",
    "    [20,10],[40,5],[10,5]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vamos a llevar un registros del punto en el que se esta quedando el modelo\n",
    "#voy a hacer una callback que guarde el último modelo, y con ello\n",
    "#vamos a ir guardando los ultimo datos de la ejecucion y si hay un problema, retornamos a ese punto\n",
    "\n",
    "#si tenemos que retomar el entrenamiento, vamos a indicar que modelo usar\n",
    "\n",
    "file_number=\"009\"\n",
    "n=18 #repes de boostrap\n",
    "#primer bucle para arquitecturas\n",
    "for i,arch in enumerate(opciones_filtros):\n",
    "    print(f\"{i}: {arch} \\n\")\n",
    "    modelo=models.model_multi_tel_energy(len_inputs=4,input_shapes=[(55,93,1)],filtros=arch,last_dense=opciones_filtros_last[i]) #no compila\n",
    "    modelo.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),loss=\"mse\",metrics=[\"mae\",\"mape\"])\n",
    "    with open(f\"{base_dir}/automat/logs/{file_number}_data_control_energy.txt\",\"a\") as registro:\n",
    "        registro.write(f\"Con arquitectura: {arch} + {opciones_filtros_last[i]}\") #, memoria {get_all_size(list(locals().items()))} Mb \\n\")\n",
    "\n",
    "    #segundo_bucle para boostrap\n",
    "    for k in range(n):\n",
    "        #modificamos el learning rate\n",
    "        if k == 7:\n",
    "            modelo.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),loss=\"mse\",metrics=[\"mae\",\"mape\"])\n",
    "        elif k == 12:\n",
    "            modelo.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),loss=\"mse\",metrics=[\"mae\",\"mape\"])\n",
    "        elif k == 15:\n",
    "            modelo.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),loss=\"mse\",metrics=[\"mae\",\"mape\"])\n",
    "\n",
    "\n",
    "        print(f\"\\n Boostrap {k+1} de {n}\")#, memoria {get_all_size(list(locals().items()))} Mb \\n\")\n",
    "\n",
    "        list_runs=new_create_main_list_runs([15,60],chose_runs)#new_create_main_list_runs([2,6,6,6,6,6,6],chose_runs)\n",
    "        with open(f\"{base_dir}/automat/logs/{file_number}_data_control_energy.txt\",\"a\") as registro:\n",
    "            registro.write(f\"Boostrap {k+1} de {n},runs: {list_runs}\")#, memoria {get_all_size(list(locals().items()))} Mb \\n\")\n",
    "        x_train_list,x_test_list,y_train_list,y_test_list=loaddata4use.load_dataset_energy(npy_final_dir,base_dir_elementos,elementos=['gamma', 'electron'],main_list_runs=list_runs,telescopios=[1,2,3,4],test_size=0.1,\n",
    "            same_quant=\"same\",verbose=True,fill=True,lower_energy_bound=0,upper_energy_bound=3)\n",
    "        print(f\"\\n Variables cargadas\")#, en memoria {get_all_size(list(locals().items()))} Mb \\n\")\n",
    "\n",
    "        x_train_list=cambiar_ejes_lista(x_train_list)\n",
    "        x_test_list=cambiar_ejes_lista(x_test_list)\n",
    "\n",
    "        \n",
    "        hist=modelo.fit(x=x_train_list,y=y_train_list,epochs=40, validation_data=(x_test_list,y_test_list),batch_size=64)\n",
    "        del x_train_list,x_test_list,y_train_list,y_test_list\n",
    "        #with open(f\"{base_dir}/automat/logs/{file_number}_data_control_energy.txt\",\"a\") as registro:\n",
    "        #    registro.write(f\"Al borrar memoria nos quedan {get_all_size(list(locals().items()))} Mb \\n\")\n",
    "        print(f\"Split hecho\")\n",
    "        modelo.save(f\"{base_dir}/modelos/{file_number}_modelo_filtro_{i}_en_boostrap_stage_{k+1}_energy.h5\")\n",
    "        with open(f\"{base_dir}/modelos/performances/{file_number}_history_modelo_filtro_{i}_en_boostrap_stage_{k+1}_energy.pickle\",\"wb\") as pick:\n",
    "            pickle.dump(hist.history,pick)    \n",
    "        gc.collect()\n",
    "    del modelo \n",
    "    gc.collect()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
